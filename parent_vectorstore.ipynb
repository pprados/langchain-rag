{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4993da90",
   "metadata": {},
   "source": [
    "# Parent vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf56f04",
   "metadata": {},
   "source": [
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "1. You may want to keep documents small, ensuring that their embeddings accurately represent their meaning. If they become too long, the embeddings can lose their meaning.\n",
    "2. You also want to maintain documents long enough to retain the context of each chunk.\n",
    "\n",
    "The `ParentDocumentVectorStore` strikes a balance by splitting and storing small chunks and different variations of data. During retrieval, it initially retrieves the small chunks but then looks up the parent IDs for those chunks and returns the larger documents.\n",
    "\n",
    "The challenge lies in correctly managing the lifecycle of the three levels of documents:\n",
    "- Original documents\n",
    "- Chunks extracted from the original documents\n",
    "- Transformations of chunks to generate more vectors for improved retrieval\n",
    "\n",
    "The `ParentDocumentVectorStore`, in combination with other components, is designed to address this challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730b0fd3-82d3-439a-87b8-3ef77d9d1d6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T08:52:17.507594776Z",
     "start_time": "2023-10-27T08:52:11.445484607Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install 'langchain-parent' openai tiktokena\n",
    "!poetry install -q  # FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631007b-61df-4a1d-93d8-e1ae6d85193e",
   "metadata": {},
   "source": [
    "For the sample, we are using the set of documents from Wikipedia.\n",
    "We would like to answer questions related to mathematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "query = \"What is the difference between pure and applied mathematics?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:52:22.086844079Z",
     "start_time": "2023-10-27T08:52:22.004004921Z"
    }
   },
   "id": "209401ccb84bfa17"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd8e4f1-7c3f-492b-b88f-fb2c9fb82d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T08:52:23.463491505Z",
     "start_time": "2023-10-27T08:52:22.737691027Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing import Union\n",
    "\n",
    "from chromadb import Documents\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "nb_documents_to_import = 3  # How many documents should be imported from Wikipedia?\n",
    "top_k = 3  # How many documents should be selected to answer the question?\n",
    "\n",
    "ROOT_PATH = tempfile._gettempdir() + \"/rag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Activate logging and prints\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def pretty_print_docs(docs: Union[str, List[Documents]], metadatas=[], kind: str = \"Variations\"):\n",
    "    def print_metadata(d):\n",
    "        s = \",\\n\".join([f\"{metadata}={repr(d.metadata.get(metadata))}\" for metadata in metadatas])\n",
    "        if s:\n",
    "            return f'\\n\\033[92m{s}\\033[0m'\n",
    "        return \"\"\n",
    "\n",
    "    def print_doc(d, i):\n",
    "        r = f\"\\033[94m{kind} {i + 1}:\\n{d.page_content[:80]}\"\n",
    "        if len(d.page_content) > 80:\n",
    "            r += f\"...[:{max(0, len(d.page_content) - 80)}]\"\n",
    "        r += f'\\033[0m{print_metadata(d)}'\n",
    "        return r\n",
    "\n",
    "    if type(docs) is list:\n",
    "        print(\n",
    "            f\"\\n{'-' * 100}\\n\".join(\n",
    "                [print_doc(d, i)\n",
    "                 for i, d in enumerate(docs)]\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        print(f'\\033[92m{docs}\\033[0m')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:00:28.901361749Z",
     "start_time": "2023-10-27T09:00:28.721309188Z"
    }
   },
   "id": "505aae5e89ee147e"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# %% Set debug and trace\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from typing import *\n",
    "\n",
    "from langchain.globals import set_debug, set_verbose\n",
    "\n",
    "set_debug(False)\n",
    "set_verbose(False)\n",
    "if True:\n",
    "    VERBOSE_INPUT = True\n",
    "    VERBOSE_OUTPUT = True\n",
    "\n",
    "\n",
    "    class ExStdOutCallbackHandler(StdOutCallbackHandler):\n",
    "        def on_text(\n",
    "                self,\n",
    "                text: str,\n",
    "                color: Optional[str] = None,\n",
    "                end: str = \"\",\n",
    "                **kwargs: Any,\n",
    "        ) -> None:\n",
    "            if VERBOSE_INPUT:\n",
    "                print(\"====\")\n",
    "                super().on_text(text=text, color=color, end=end)\n",
    "\n",
    "        def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> None:\n",
    "            \"\"\"Ajoute une trace des outputs du llm\"\"\"\n",
    "            if VERBOSE_OUTPUT:\n",
    "                print(\"\\n\\033[1m> Finished chain with\\033[0m\")\n",
    "                knows_keys = {\n",
    "                    \"answer\",\n",
    "                    \"output_text\",\n",
    "                    \"text\",\n",
    "                    \"result\",\n",
    "                    \"outputs\",\n",
    "                    \"output\",\n",
    "                }\n",
    "                if \"outputs\" in outputs:\n",
    "                    print(\"\\n\\033[33m\")\n",
    "                    print(\n",
    "                        \"\\n---\\n\".join(\n",
    "                            [text[\"text\"].strip() for text in outputs[\"outputs\"]]\n",
    "                        )\n",
    "                    )\n",
    "                    print(\"\\n\\033[0m\")\n",
    "                elif knows_keys.intersection(outputs):\n",
    "                    # Prend la première cles en intersection\n",
    "                    print(\n",
    "                        f\"\\n\\033[33m{outputs[next(iter(knows_keys.intersection(outputs)))]}\\n\\033[0m\"\n",
    "                    )\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "\n",
    "    CALLBACKS = [ExStdOutCallbackHandler()]\n",
    "else:\n",
    "    CALLBACKS = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T08:52:25.096864857Z",
     "start_time": "2023-10-27T08:52:24.809451085Z"
    }
   },
   "id": "a8f4ebede9975d0e"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af6a3c4bb3423122",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:00:40.099029282Z",
     "start_time": "2023-10-27T09:00:32.812813149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mDocuments 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3920]\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mDocuments 2:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:3920]\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mDocuments 3:\n",
      "Mathematical Reviews is a journal published by the American Mathematical Society...[:3920]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade pip langchain wikipedia\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "\n",
    "documents = WikipediaRetriever(top_k_results=nb_documents_to_import).get_relevant_documents(\"mathematic\")\n",
    "pretty_print_docs(documents, kind=\"Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642f89f-15f9-4a65-86ad-9c8403393d14",
   "metadata": {},
   "source": [
    "# Select provider\n",
    "## Select the LLM\n",
    "Before starting, we need to:\n",
    "- Set the environment variables\n",
    "- Choose a language model (LLM), determine the context size, and set the maximum number of tokens for generation\n",
    "- Enable all caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa8340e2-1b4a-4b93-b407-268f8a698496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:00:54.486452298Z",
     "start_time": "2023-10-27T09:00:54.420971314Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"XXXXX\"\n",
    "if \"COHERE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"COHERE_API_KEY\"] = \"XXXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee04f135-a013-47e4-9d18-2fe35896787c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:00.014212623Z",
     "start_time": "2023-10-27T09:00:56.078246084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(512, 51, 461)"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --quiet openai tiktoken\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "context_size = 512  # For the demonstration use a smal context_size.\n",
    "max_tokens = int(context_size * (10 / 100))  # 10% for the response\n",
    "max_input_tokens = context_size - max_tokens\n",
    "llm = OpenAI(\n",
    "    max_tokens=max_tokens,\n",
    ")\n",
    "context_size, max_tokens, max_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# Add a cache\n",
    "from langchain.cache import SQLiteCache\n",
    "import langchain\n",
    "\n",
    "LANCHAIN_CACHE_PATH = ROOT_PATH + \"/cache_llm\"\n",
    "langchain.llm_cache = SQLiteCache(database_path=LANCHAIN_CACHE_PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:00.112825360Z",
     "start_time": "2023-10-27T09:01:00.003887300Z"
    }
   },
   "id": "3e12bd3f44158a74"
  },
  {
   "cell_type": "markdown",
   "id": "9cd2a2d9-de21-4336-9711-413f1e9c83b4",
   "metadata": {},
   "source": [
    "## Select the embedding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e3ce9c7-fafc-493e-b5b4-93f64f81a8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:00.114856193Z",
     "start_time": "2023-10-27T09:01:00.043835916Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54cc5d45-573b-4540-8738-16115818a9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:00.248422717Z",
     "start_time": "2023-10-27T09:01:00.085582777Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a cache\n",
    "CACHE_EMBEDDING_PATH = ROOT_PATH + \"/cache_embedding\"\n",
    "from langchain.storage import LocalFileStore\n",
    "\n",
    "fs = LocalFileStore(CACHE_EMBEDDING_PATH)\n",
    "\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, fs, namespace=embeddings.model if hasattr(embeddings, \"model\") else \"unknown\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ff47d-933e-47be-9849-bccc78cf9309",
   "metadata": {},
   "source": [
    "# Transform documents\n",
    "The idea is to transform a document into multiple versions and calculate a vector for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "97b6e300-50f4-41ae-a524-05030c2c865c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:01.540401289Z",
     "start_time": "2023-10-27T09:01:01.425233211Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import *\n",
    "from langchain_parent.document_transformers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e513cf-6ac8-4121-81b9-b961afd52d6f",
   "metadata": {},
   "source": [
    "The first step is to split the document to ensure compatibility with the `max_input_tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f7a03e9-993c-4208-bfc2-b27199214fa9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:03.669504790Z",
     "start_time": "2023-10-27T09:01:03.464953137Z"
    }
   },
   "outputs": [],
   "source": [
    "parent_transformer = TokenTextSplitter(\n",
    "    chunk_size=max_input_tokens,\n",
    "    chunk_overlap=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640d55a-a466-4de1-abfe-4d5c1d2d76a3",
   "metadata": {},
   "source": [
    "Let's test the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbb10dc0-6cf2-4e14-b55c-bb846ba97515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:19.288765468Z",
     "start_time": "2023-10-27T09:01:19.169978394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'before:3 documents, after:6 chunks'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_documents = parent_transformer.transform_documents(documents)\n",
    "f\"before:{len(documents)} documents, after:{len(chunk_documents)} chunks\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We need multiple variations for each chunk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79651e78d2831fcc"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09aa4959-1325-43cd-a22e-0f7c983c8be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:24.180582477Z",
     "start_time": "2023-10-27T09:01:24.064570560Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_transformer = DocumentTransformers(\n",
    "    transformers=[\n",
    "        GenerateQuestionsTransformer.from_llm(llm),\n",
    "        SummarizeTransformer.from_llm(llm),\n",
    "        CopyDocumentTransformer(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74358ce-b013-4729-a71b-ee4c82f0d51f",
   "metadata": {},
   "source": [
    "Note that we require all transformations for each chunk, including the original chunk. This is why we include the `CopyDocumentTransformer()`.\n",
    "\n",
    "Now, let's test the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "What are the major subdisciplines of mathematics? \u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "What are the fundamental truths of mathematics?\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "How has the development of mathematics been impacted by scientific discoveries?\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "SUMMARY:\n",
      "Mathematics is an academic discipline which involves the study of numbe...[:192]\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 5:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "variations_of_chunks = chunk_transformer.transform_documents(chunk_documents[:1])\n",
    "# Select the variations for the first chunk\n",
    "pretty_print_docs(variations_of_chunks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:01:30.897768429Z",
     "start_time": "2023-10-27T09:01:30.807460079Z"
    }
   },
   "id": "63cf0377ba48d2ad"
  },
  {
   "cell_type": "markdown",
   "id": "9a594c2a-1ddc-4eb7-a7ba-922923fe5dae",
   "metadata": {},
   "source": [
    "# Saving all Variations in a Vector Store\n",
    "Now, our goal is to store the chunks and their respective variations in a vector store. During retrieval, the process begins by fetching the smaller chunks but then involves looking up the parent IDs for those chunks and returning the original chunk.\n",
    "\n",
    "A specialized vector store is designed for this purpose: the `RAGVectorStore`.\n",
    "It's not a standalone vector store but rather a wrapper for another vector store. When you add a document, the document undergoes transformation with the `parent_transformer`, and each chunk is enriched with various versions through the `chunk_transformer`.\n",
    "\n",
    "First, we need to create some persistent components:\n",
    "- A standard vector store\n",
    "- A document store to store each original chunk returned by the retriever and the relationship between the document and chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc155113-dd16-4c73-a13c-80d428bd7923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:02:34.390971124Z",
     "start_time": "2023-10-27T09:02:34.036182974Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "VS_PATH = ROOT_PATH + \"/vs\"\n",
    "chroma_vectorstore = Chroma(\n",
    "    collection_name=\"all_variations_of_chunks\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=VS_PATH,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2d189e7e-3e59-43f0-9a8c-92fd7844c393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:02:36.372281394Z",
     "start_time": "2023-10-27T09:02:36.265446536Z"
    }
   },
   "outputs": [],
   "source": [
    "DOCSTORE_PATH = ROOT_PATH + \"/chunks\"\n",
    "from langchain.storage import EncoderBackedStore\n",
    "from langchain.storage import LocalFileStore\n",
    "import pickle\n",
    "\n",
    "docstore = EncoderBackedStore[str, Document](\n",
    "    store=LocalFileStore(root_path=DOCSTORE_PATH),\n",
    "    key_encoder=lambda x: x,\n",
    "    value_serializer=pickle.dumps,\n",
    "    value_deserializer=pickle.loads\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266663f2-bb6a-46dd-84cc-0ec67a5bf24e",
   "metadata": {},
   "source": [
    "All documents must have a unique ID in their metadata. \n",
    "Then, it's possible to use the advanced `RAGVectorStore`. \n",
    "It's a wrapper around a standard vector store, specialized for managing different transformations and the lifecycle of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4fafbad-c577-40ae-8543-a145d9ca7f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:02:40.736641175Z",
     "start_time": "2023-10-27T09:02:40.617206962Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_parent.vectorstores import RAGVectorStore\n",
    "\n",
    "vectorstore = RAGVectorStore(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    docstore=docstore,\n",
    "    doc_id_key=\"source\",  # Uniq id of documents\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039782f-9f63-4885-be09-ba9f7555b2cb",
   "metadata": {},
   "source": [
    "Now, it's time to add documents to this vector store.\n",
    "- If the `parent_transformer` is set, the document is transformed into a new list of chunk documents (generally, this is a split phase).\n",
    "- Then, if the `chunk_transformer` is set, each chunk document is transformed to generate some variations.\n",
    "- Each transformation of all chunks is added to the destination vector store (in this case, it's referred to as \"chroma\").\n",
    "- All chunks are saved in the DocStore with the list of all associated variations.\n",
    "- All IDs of chunks generated for each document are saved in the doc store. This makes it possible to remove the document and all associated chunks when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecd8eba9-36aa-4ed6-b32d-a7eef48289a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T09:02:45.653299959Z",
     "start_time": "2023-10-27T09:02:45.295408365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "['6d90af33d816d1b2c2a2e9d277e72862ff076c265da2756ece7d15a517070f5f',\n '492c728729e2274e2af6984dbc84d61d52f4799b7215fe175ad2b4c483a95449',\n '59dd02283f9dcfdbb7cf7f1ae11dcbe986a8e2621aa92c5dbf31be9bc1b07d3b']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = vectorstore.add_documents(documents)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "While conducting the search, an embedding is computed for the query and subsequently compared to the embeddings of all the transformed chunks. The metadata for each transformed chunk contains a reference to the ID of the original chunk, allowing for the retrieval of the respective chunk."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "805a0119fbd62cda"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92m_chunk_id='16d37178-1381-4e53-adab-e1a23f5880a9'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92m_chunk_id='16312617-31a9-4860-b65a-a3cccf0f3f57'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92m_chunk_id='d7ee4e45-a7c0-402b-861e-7a4c58c6d9b1'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92m_chunk_id='a4de2c58-0f54-40c4-8f0f-54adeb3babd0'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(vectorstore.search(query=query, search_type=\"similarity\"),[\"_chunk_id\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:08:53.136230085Z",
     "start_time": "2023-10-27T09:08:52.693645088Z"
    }
   },
   "id": "a15b4c8ac0660246"
  },
  {
   "cell_type": "markdown",
   "id": "a5c5c65eac9a6017",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The IDs consist of a list of document IDs. You can utilize these IDs to remove all related chunks and variations.\n",
    "\n",
    "When you examine the langchain API, you may wonder where to store the document IDs from the vector store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba9eb40d3768f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Index Vector Store\n",
    "To manage the lifecycle of the documents in the vector store, you can utilize an `index()`.\n",
    "A `RecordManager` can keep track of the evolution of each document. Use `index()` to import the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d3ea4486d47ea54",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:09:54.624761585Z",
     "start_time": "2023-10-27T09:09:54.534241617Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import index, SQLRecordManager\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace=\"record_manager_cache\",\n",
    "    db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\"\n",
    ")\n",
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29511638aa0cf089",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:09:56.819176138Z",
     "start_time": "2023-10-27T09:09:56.706038167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'num_added': 1, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 0}"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save all the information in:\n",
    "# - record manager\n",
    "# - docstore\n",
    "# - vectorstore\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you import the same documents, you will notice that all documents are skipped. Without using `index()`, the same document will be present twice. This has the same effect as dividing the `top_k` by two during the search!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95ff9c58b897997"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "{'num_added': 0, 'num_updated': 0, 'num_skipped': 3, 'num_deleted': 0}"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index(\n",
    "    docs_source=documents,  # PPR: on peut y placer un loader\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:10:08.837506005Z",
     "start_time": "2023-10-27T09:10:08.733733627Z"
    }
   },
   "id": "ea7c3fdc0ec4c5fd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If your document is changed, the previous version is deleted."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4926718dd8c6b87"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/pprados/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'num_added': 1, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 1}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content += \" Is changed.\"\n",
    "index(\n",
    "    docs_source=documents,  # PPR: on peut y placer un loader\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:10:16.163291209Z",
     "start_time": "2023-10-27T09:10:16.026714828Z"
    }
   },
   "id": "892dd66e8de8dc70"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To delete the old records, use the `full` strategy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "348aa8c04f101a3b"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "{'num_added': 0, 'num_updated': 0, 'num_skipped': 2, 'num_deleted': 1}"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del documents[0]\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"full\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:11:14.569559217Z",
     "start_time": "2023-10-27T09:11:14.458614635Z"
    }
   },
   "id": "849c68d044cfeef5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: LongContextReorder, OpenAIMetadataTagger"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21ca3e056ffabdf3"
  },
  {
   "cell_type": "markdown",
   "id": "53ec51edafcdd6d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It's important to note that there are three ways to save parts of the data:\n",
    "\n",
    "- In the *vector store*: this includes the bucket, metadata, and the associated embedding vectors.\n",
    "- In the *doc store*: this covers the original bucket and the relationship between parent and chunks before the *chunk transformations*.\n",
    "- In the *SQLRecordManager*: this involves the references of the parent document or chunks.\n",
    "\n",
    "Each source does not manage transactions. If a problem occurs while adding a document, it is highly likely that the sources will be inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981b01e756e9096",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use advanced retrievers\n",
    "Just like with the standard vector store, you can convert the `RAGVectorStore` into a `Retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ec70b4b3dcc80eb8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:12:05.784188549Z",
     "start_time": "2023-10-27T09:12:05.205718726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "selected_chunks = retriever.get_relevant_documents(query)\n",
    "len(selected_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79dba17a046faa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Specialized Retrievers\n",
    "It's possible to combine multiple retrievers or use specialized retrievers for advanced applications."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `SelfQueryRetriever` can generate a metadata filter. We use it to provide the option to filter the chunks by the title of the original document."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da5f219067ca4a98"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      " of these traditions were the mathematics developed by the Maya civilization of ...[:1666]\u001B[0m\n",
      "\u001B[92mtitle='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      " of these traditions were the mathematics developed by the Maya civilization of ...[:1666]\u001B[0m\n",
      "\u001B[92mtitle='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      " of these traditions were the mathematics developed by the Maya civilization of ...[:1666]\u001B[0m\n",
      "\u001B[92mtitle='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "The history of mathematics deals with the origin of discoveries in mathematics a...[:2174]\u001B[0m\n",
      "\u001B[92mtitle='History of mathematics'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Documents on mathematics\"\n",
    "self_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True)\n",
    "\n",
    "pretty_print_docs(self_retriever.get_relevant_documents(\"In the document 'History of mathematics', \" + query),\n",
    "                  [\"title\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:12:23.477931998Z",
     "start_time": "2023-10-27T09:12:22.819855342Z"
    }
   },
   "id": "d3b8ab4707aef773"
  },
  {
   "cell_type": "markdown",
   "source": [
    "It's possible to use it with the variations, but you must directly use the `chroma_vectorstore`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "715f98bdc3a46341"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "\n",
      "The history of mathematics deals with the development of mathematical methods a...[:704]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer',\n",
      "title='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "\n",
      "The history of mathematics deals with the development of mathematical methods a...[:704]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer',\n",
      "title='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "\n",
      "The history of mathematics deals with the development of mathematical methods a...[:704]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer',\n",
      "title='History of mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "SUMMARY:\n",
      "\n",
      "The history of mathematics deals with the development of mathematical ...[:212]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer',\n",
      "title='History of mathematics'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"transformer\",\n",
    "        description=\"The transformations of the documents. \"\n",
    "                    \"Must be GenerateQuestionsTransformer or SummarizeTransformer.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"documents on mathematics\"\n",
    "chroma_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    chroma_vectorstore,  # In this case, use the chroma vectorstore, to retrieve the variations\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    verbose=True)\n",
    "\n",
    "pretty_print_docs(chroma_retriever.get_relevant_documents(\"Sumarize of 'History of mathematic\"),\n",
    "                  [\"transformer\", \"title\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:13:45.940138202Z",
     "start_time": "2023-10-27T09:13:45.590721747Z"
    }
   },
   "id": "bb37cd27f4cf4b92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "With filter, we can obtain a retriever specialized in summaries."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "161e243eadf938e2"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "summary_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"transformer\": {\"$eq\": \"SummarizeTransformer\"}}})\n",
    "pretty_print_docs(summary_retriever.get_relevant_documents(query), [\"transformer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:15:06.088237701Z",
     "start_time": "2023-10-27T09:15:05.641886864Z"
    }
   },
   "id": "29aca35b60b7c847"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And combine it with the chunk retriever."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30c261a17c2a969d"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 5:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 6:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 7:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 8:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.merger_retriever import MergerRetriever\n",
    "\n",
    "merge_retriever = MergerRetriever(retrievers=[self_retriever, summary_retriever])\n",
    "pretty_print_docs(merge_retriever.get_relevant_documents(query), [\"transformer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:15:16.556351517Z",
     "start_time": "2023-10-27T09:15:15.841727467Z"
    }
   },
   "id": "5bdf6111bcbfc6c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieval results may vary with minor changes in query phrasing or if the embeddings do not accurately capture the data's semantics. The `MultiQueryRetriever` streamlines the prompt-tuning process by employing an LLM to generate multiple queries from diverse perspectives based on a user input query. For each query, it retrieves a collection of pertinent documents and combines the unique results from all queries to obtain a larger set of potentially relevant documents."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5577ae97cec80e50"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 4:\n",
      "Mathematics is an area of knowledge that includes topics such as numbers, formul...[:497]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 5:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 6:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 7:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92mtransformer=None\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 8:\n",
      "\n",
      "Mathematics is an ancient field of study derived from the Greek word máthēma, m...[:490]\u001B[0m\n",
      "\u001B[92mtransformer='SummarizeTransformer'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "# Generate 3 questions from the user questions, and these version to find a better candidats in vectorstore\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=merge_retriever,\n",
    ")\n",
    "\n",
    "pretty_print_docs(multi_query_retriever.get_relevant_documents(query),[\"transformer\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:17:30.684104291Z",
     "start_time": "2023-10-27T09:17:28.816949303Z"
    }
   },
   "id": "a3be992243890cc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "At this stage, when we employ the retriever:\n",
    "\n",
    "- Multiple queries are generated to locate the relevant documents (via `multi_query_retriever`).\n",
    "- For each query:\n",
    "    - Both the original chunk and the chunk summary are retrieved.\n",
    "    - If feasible, a metadata filter is applied (via `self_retriever`).\n",
    "    - The query vector is compared to all variations of each chunk.\n",
    "    - The best variations are retrieved, but only a subset of the original chunks is utilized (via `RAGVectorStore`).\n",
    "- Only this selected candidate can be used to answer a question."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3369a18f602a1b83"
  },
  {
   "cell_type": "markdown",
   "id": "e231bfd97367dc51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Use a compressor\n",
    "It's possible to use a *compressor*, to filter the selection.\n",
    "\n",
    "You can combine some filter in a pipeline.\n",
    "- The [CohereRerank](https://python.langchain.com/docs/integrations/retrievers/cohere-reranker) can rank the chunks.\n",
    "- The [EmbeddingsFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#embeddingsfilter) can add a similarity threshold\n",
    "- The [LLMChainFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#llmchainfilter) decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccfc7ec65f722b9e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:19:56.044717064Z",
     "start_time": "2023-10-27T09:19:53.371106382Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q cohere\n",
    "from langchain.retrievers.document_compressors import CohereRerank\n",
    "\n",
    "cohere_rerank = CohereRerank(top_n=top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "67cbede89e25ee4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:20:00.768751882Z",
     "start_time": "2023-10-27T09:19:57.400624278Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install -q simsimd\n",
    "from langchain.retrievers.document_compressors import *\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,\n",
    "    similarity_threshold=0.7  # Threshold for determining when two documents are redundant.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "# Combine compressors\n",
    "compressor = DocumentCompressorPipeline(\n",
    "    transformers=[\n",
    "        # embeddings_filter,\n",
    "        cohere_rerank,\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:33.677972765Z",
     "start_time": "2023-10-27T09:30:33.534461383Z"
    }
   },
   "id": "2d1371cafbc000ab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, we can a filter with our pipeline."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a10c8c0a080849fd"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=multi_query_retriever\n",
    ")\n",
    "\n",
    "pretty_print_docs(compression_retriever.get_relevant_documents(query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:37.075570860Z",
     "start_time": "2023-10-27T09:30:35.099368508Z"
    }
   },
   "id": "537aa32a60d7b71d"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "final_retriever = compression_retriever"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:37.181246385Z",
     "start_time": "2023-10-27T09:30:37.072434728Z"
    }
   },
   "id": "c613c2674527f644"
  },
  {
   "cell_type": "markdown",
   "id": "13e195db90457352",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Asking a Question\n",
    "\n",
    "Now, it's possible to utilize this architecture to pose a question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "\n",
    "# FIXME\n",
    "reload(logging)\n",
    "logging.getLogger(\"langchain.retrievers.self_query.base\").setLevel(logging.WARN)\n",
    "logging.getLogger().setLevel(logging.WARN)  # Deactivate the logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:38.035510367Z",
     "start_time": "2023-10-27T09:30:37.920677956Z"
    }
   },
   "id": "dcc787c918e6bdeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "A problem can arise if the number of documents to be analysed is too large for the size of the prompt.\n",
    "Several strategies are available to manage this, identified by the \n",
    "[`chain_type`](https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa#chain-type) parameter."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e146b3fb5aa1a8c4"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pure mathematics is developed independently from any application, while applied mathematics is developed in close correlation with its applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",  # or \"map_reduce\", \"refine\", \"map_rerank\"\n",
    ")\n",
    "result = chain(\n",
    "    {\n",
    "        \"input_documents\": final_retriever.get_relevant_documents(query),\n",
    "        \"question\": query,\n",
    "    }\n",
    ")\n",
    "print(result[\"output_text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:43.346599586Z",
     "start_time": "2023-10-27T09:30:40.800536786Z"
    }
   },
   "id": "528d6cea511e95c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the documents have `sources` and the URLs are not too large, you can use `RetrievalQAWithSourcesChain`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5178548aed66397"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pure mathematics is the study of mathematics for its own sake, without any practical application. Applied mathematics is the application of mathematics to solve problems in other fields.\n",
      "\n",
      "\u001B[92mhttps://en.wikipedia.org/wiki/Mathematics\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=final_retriever,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"sources\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:47.133490452Z",
     "start_time": "2023-10-27T09:30:43.337548723Z"
    }
   },
   "id": "82d24ebb6d278bac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For more precise control over the document references used, opt for `RetrievalQAWithReferencesChain`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4b2b04514f3b73"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: syntax error near unexpected token `&'\r\n",
      "/bin/bash: -c: line 1: `cd../langchain-qa_with_references/ & & poetry install'\r\n"
     ]
    }
   ],
   "source": [
    "# FIXME\n",
    "#!pip install -q langchain_qa_with_references\n",
    "!cd../langchain-qa_with_references/ & & poetry install"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:47.368314026Z",
     "start_time": "2023-10-27T09:30:47.133615978Z"
    }
   },
   "id": "146deea68dbc801f"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure mathematics is the study of mathematics for its own sake, while applied mathematics is the use of mathematics to solve problems in other disciplines.\n",
      "\u001B[94mVariations 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 2:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001B[0m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001B[94mVariations 3:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:2472]\u001B[0m\n",
      "\u001B[92msource='https://en.wikipedia.org/wiki/Mathematics'\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesChain\n",
    "\n",
    "chain = RetrievalQAWithReferencesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=final_retriever,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"source_documents\"], ['source'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:30:49.404724872Z",
     "start_time": "2023-10-27T09:30:47.293652325Z"
    }
   },
   "id": "7eeda26fec5e810a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly, if you wish to identify the specific text fragments utilized by the LLM to formulate its response, select the `RetrievalQAWithReferencesAndVerbatimsChain` option."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bcd89050a21022f"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQAWithReferencesAndVerbatimsChain chain...\u001B[0m\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Failed to parse Verbatims from completion \n{\n  \"response\": \"Pure mathematics is the study of abstract concepts such as number theory and algebra, while applied mathematics uses these concepts to solve real-world problems. \",\n  \"documents\": [\n    {\n      \"ids. Got: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/output_parsers/pydantic.py:27\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     26\u001B[0m     json_str \u001B[38;5;241m=\u001B[39m match\u001B[38;5;241m.\u001B[39mgroup()\n\u001B[0;32m---> 27\u001B[0m json_object \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpydantic_object\u001B[38;5;241m.\u001B[39mparse_obj(json_object)\n",
      "File \u001B[0;32m/usr/lib/python3.10/json/__init__.py:359\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    358\u001B[0m     kw[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparse_constant\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m parse_constant\n\u001B[0;32m--> 359\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03mcontaining a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m/usr/lib/python3.10/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mOutputParserException\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[93], line 9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_qa_with_references\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchains\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RetrievalQAWithReferencesAndVerbatimsChain\n\u001B[1;32m      3\u001B[0m chain \u001B[38;5;241m=\u001B[39m RetrievalQAWithReferencesAndVerbatimsChain\u001B[38;5;241m.\u001B[39mfrom_chain_type(\n\u001B[1;32m      4\u001B[0m     llm\u001B[38;5;241m=\u001B[39mllm,\n\u001B[1;32m      5\u001B[0m     chain_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmap_reduce\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m     retriever\u001B[38;5;241m=\u001B[39mfinal_retriever,\n\u001B[1;32m      7\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mCALLBACKS,\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m----> 9\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mchain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     11\u001B[0m pretty_print_docs(result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource_documents\u001B[39m\u001B[38;5;124m\"\u001B[39m], [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbatims\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/base.py:310\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    309\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    311\u001B[0m run_manager\u001B[38;5;241m.\u001B[39mon_chain_end(outputs)\n\u001B[1;32m    312\u001B[0m final_outputs: Dict[\u001B[38;5;28mstr\u001B[39m, Any] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprep_outputs(\n\u001B[1;32m    313\u001B[0m     inputs, outputs, return_only_outputs\n\u001B[1;32m    314\u001B[0m )\n",
      "File \u001B[0;32m~/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/chains/base.py:304\u001B[0m, in \u001B[0;36mChain.__call__\u001B[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001B[0m\n\u001B[1;32m    297\u001B[0m run_manager \u001B[38;5;241m=\u001B[39m callback_manager\u001B[38;5;241m.\u001B[39mon_chain_start(\n\u001B[1;32m    298\u001B[0m     dumpd(\u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    299\u001B[0m     inputs,\n\u001B[1;32m    300\u001B[0m     name\u001B[38;5;241m=\u001B[39mrun_name,\n\u001B[1;32m    301\u001B[0m )\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    303\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m--> 304\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrun_manager\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m new_arg_supported\n\u001B[1;32m    306\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(inputs)\n\u001B[1;32m    307\u001B[0m     )\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    309\u001B[0m     run_manager\u001B[38;5;241m.\u001B[39mon_chain_error(e)\n",
      "File \u001B[0;32m~/workspace.bda/langchain-qa_with_references/langchain_qa_with_references/chains/qa_with_references/base.py:248\u001B[0m, in \u001B[0;36mBaseQAWithReferencesChain._call\u001B[0;34m(self, inputs, run_manager)\u001B[0m\n\u001B[1;32m    238\u001B[0m     doc\u001B[38;5;241m.\u001B[39mmetadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_idx_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    240\u001B[0m answers \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcombine_documents_chain(\n\u001B[1;32m    241\u001B[0m     {\n\u001B[1;32m    242\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcombine_documents_chain\u001B[38;5;241m.\u001B[39minput_key: docs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    246\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39m_run_manager\u001B[38;5;241m.\u001B[39mget_child(),\n\u001B[1;32m    247\u001B[0m )\n\u001B[0;32m--> 248\u001B[0m answer, all_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43manswers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m selected_docs \u001B[38;5;241m=\u001B[39m [docs[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m all_idx \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mlen\u001B[39m(docs)]\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manswer_key: answer,\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_documents_key: selected_docs,\n\u001B[1;32m    254\u001B[0m }\n",
      "File \u001B[0;32m~/workspace.bda/langchain-qa_with_references/langchain_qa_with_references/chains/qa_with_references/base.py:196\u001B[0m, in \u001B[0;36mBaseQAWithReferencesChain._process_results\u001B[0;34m(self, answers, docs, run_manager)\u001B[0m\n\u001B[1;32m    193\u001B[0m     parser \u001B[38;5;241m=\u001B[39m llm_chain\u001B[38;5;241m.\u001B[39mprompt\u001B[38;5;241m.\u001B[39moutput_parser\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m parser\n\u001B[0;32m--> 196\u001B[0m references \u001B[38;5;241m=\u001B[39m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43manswer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m answer \u001B[38;5;241m=\u001B[39m references\u001B[38;5;241m.\u001B[39mresponse\n\u001B[1;32m    199\u001B[0m idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_reference(answers, docs, references)\n",
      "File \u001B[0;32m~/workspace.bda/langchain-parent/.venv/lib/python3.10/site-packages/langchain/output_parsers/pydantic.py:33\u001B[0m, in \u001B[0;36mPydanticOutputParser.parse\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m     31\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpydantic_object\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m     32\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to parse \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from completion \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. Got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m OutputParserException(msg, llm_output\u001B[38;5;241m=\u001B[39mtext)\n",
      "\u001B[0;31mOutputParserException\u001B[0m: Failed to parse Verbatims from completion \n{\n  \"response\": \"Pure mathematics is the study of abstract concepts such as number theory and algebra, while applied mathematics uses these concepts to solve real-world problems. \",\n  \"documents\": [\n    {\n      \"ids. Got: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "from langchain_qa_with_references.chains import RetrievalQAWithReferencesAndVerbatimsChain\n",
    "\n",
    "chain = RetrievalQAWithReferencesAndVerbatimsChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=final_retriever,\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "result = chain(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"source_documents\"], [\"source\", \"verbatims\"])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-27T09:33:10.860170793Z",
     "start_time": "2023-10-27T09:33:07.440057347Z"
    }
   },
   "id": "48e8463e7d781f6"
  },
  {
   "cell_type": "markdown",
   "id": "ae103224-11fd-4955-bb77-b808332539f6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Short version\n",
    "It's time to simplify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "!pip install -q langchain-parent openai tiktoken langchain wikipedia cohere simsimd langchain_qa_with_references"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be36df460d518359"
  },
  {
   "cell_type": "markdown",
   "id": "5912e70d-019c-4b62-a81d-ee60d3e5fa40",
   "metadata": {},
   "source": [
    "## Prepare the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tempfile\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_parent.vectorstores import RAGVectorStore\n",
    "from langchain_parent.document_transformers import *\n",
    "import langchain\n",
    "from langchain.cache import *\n",
    "from langchain.chains import *\n",
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.embeddings import *\n",
    "from langchain.indexes import *\n",
    "from langchain.llms import *\n",
    "from langchain.retrievers import *\n",
    "from langchain.retrievers.document_compressors import *\n",
    "from langchain.storage import *\n",
    "from langchain.text_splitter import *\n",
    "from langchain.vectorstores import Chroma\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34e11d75528c6a88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20db69d-d26f-4bb7-b272-d03f780abfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "id_key = 'id'\n",
    "nb_documents_to_import = 4\n",
    "\n",
    "context_size = 512  # For the demonstration use a smal context_size.\n",
    "max_tokens = int(context_size * (10 / 100))  # 10% for the response\n",
    "max_input_tokens = context_size - max_tokens\n",
    "\n",
    "ROOT_PATH = tempfile._gettempdir() + \"/rag\"\n",
    "if not os.path.exists(ROOT_PATH):\n",
    "    os.makedirs(ROOT_PATH)\n",
    "DOCSTORE_PATH = ROOT_PATH + \"/chunks\"\n",
    "VS_PATH = ROOT_PATH + \"/vs\"\n",
    "LANCHAIN_CACHE_PATH = ROOT_PATH + \"/cache_llm\"\n",
    "\n",
    "# %%\n",
    "llm = OpenAI()\n",
    "langchain.llm_cache = SQLiteCache(database_path=LANCHAIN_CACHE_PATH)\n",
    "\n",
    "# %%\n",
    "CACHE_EMBEDDING_PATH = ROOT_PATH + \"/cache_embedding\"\n",
    "\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    OpenAIEmbeddings(),\n",
    "    LocalFileStore(CACHE_EMBEDDING_PATH),\n",
    "    namespace=\"cache\"\n",
    ")\n",
    "\n",
    "docstore = EncoderBackedStore[str, Document](\n",
    "    store=LocalFileStore(root_path=DOCSTORE_PATH),\n",
    "    key_encoder=lambda x: x,\n",
    "    value_serializer=pickle.dumps,\n",
    "    value_deserializer=pickle.loads\n",
    ")\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace=\"record_manager_cache\",\n",
    "    db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\"\n",
    ")\n",
    "record_manager.create_schema()\n",
    "\n",
    "parent_transformer = TokenTextSplitter(\n",
    "    chunk_size=max_input_tokens,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "chunk_transformer = DocumentTransformers(\n",
    "    transformers=[\n",
    "        # GenerateQuestionsTransformer.from_llm(llm),\n",
    "        SummarizeTransformer.from_llm(llm),\n",
    "        # CopyDocumentTransformer(),\n",
    "    ]\n",
    ")\n",
    "vectorstore = RAGVectorStore(\n",
    "    vectorstore=Chroma(\n",
    "        collection_name=\"all_variations_of_chunks\",\n",
    "        persist_directory=VS_PATH,\n",
    "        embedding_function=embeddings\n",
    "    ),\n",
    "    docstore=docstore,\n",
    "    doc_id_key=\"source\",\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f250e7c-cdde-4e05-9f33-bc8f3270b096",
   "metadata": {},
   "source": [
    "## Import the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82442fca-e199-4652-954b-01aebc8a9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = WikipediaRetriever(top_k_results=nb_documents_to_import).get_relevant_documents(\"mathematic\")\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    record_manager=record_manager,\n",
    "    vector_store=vectorstore,\n",
    "    cleanup=\"incremental\",\n",
    "    source_id_key=\"source\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c57196-57d4-42fa-ad60-28e59792b340",
   "metadata": {},
   "source": [
    "## Refine the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=\"Documents on mathematics\",\n",
    "    metadata_field_info=[\n",
    "        AttributeInfo(\n",
    "            name=\"title\",\n",
    "            description=\"The title of the document.\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "    ],\n",
    "    verbose=True)\n",
    "\n",
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=DocumentCompressorPipeline(\n",
    "        transformers=[\n",
    "            EmbeddingsFilter(\n",
    "                embeddings=embeddings,\n",
    "                similarity_threshold=0.7\n",
    "            ),\n",
    "            CohereRerank(top_n=top_k),\n",
    "        ]\n",
    "    ),\n",
    "    base_retriever=retriever\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "314be417eee3563d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ask a question"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aec21907130c0fd3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "query = \"what is the major mathematical disciplines ?\"\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "result = chain(query)\n",
    "pprint(result)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ab6cd6a2fcae0d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(ROOT_PATH)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49beb23b22096ce2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODO: https://www.google.com/search?q=site%3Adrive.google.com+inurl%3Afolders+datasience\n",
    "#Pour rechercher des folders GDrive pour source de doc\n",
    "# https://drive.google.com/drive/folders/1i3jXi0o-COk7L9Mfrg55Ysae8cdEIAHU"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d58cc6c1547298e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-parent",
   "language": "python",
   "name": "langchain-parent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
