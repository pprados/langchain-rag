{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4993da90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# RAG vectorstore\n",
    "\n",
    "[![Open in Colab](colab-badge.svg)](https://colab.research.google.com/github/pprados/langchain-rag/blob/master/docs/integrations/vectorstores/rag_vectorstore.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf56f04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "RAG architectures are very popular. They can be quickly demonstrated on a few documents. For a production project, more effort is needed to achieve an effective architecture.\n",
    "\n",
    "The basic principle is to divide a document into chunks, place them in a vector database, then select the chunks closest to the question and inject them into a prompt.\n",
    "\n",
    "When splitting documents for retrieval, there are often conflicting desires:\n",
    "\n",
    "1. You may want to keep documents small, ensuring that their embeddings accurately represent their meaning. If they become too long, the embeddings can lose their meaning.\n",
    "2. You also want to maintain documents long enough to retain the context of each chunk.\n",
    "\n",
    "When you have a lot of documents, and therefore a lot of pieces, it's likely that dozens of pieces have a distance close to the question. Taking only the top 4 is not a good idea. The answer may lie in the 6 or 7 tracks. How can we improve the match between the question and a fragment? By preparing several versions of the fragment, each with an embedding. In this way, one of the versions can be closer to the question than the original fragment. This version is stripped of context. But the context is still needed to answer the question correctly. One strategy consists of breaking down each fragment into different versions, but using the retriever to return to the original fragment. \n",
    "\n",
    "The `RAGVectorStore` strikes a balance by splitting and storing small chunks and different variations of data. During retrieval, it initially retrieves the small chunks but then looks up the parent IDs for those chunks and returns the larger documents.\n",
    "\n",
    "The challenge lies in correctly managing the lifecycle of the three levels of documents:\n",
    "- Original documents\n",
    "- Chunks extracted from the original documents\n",
    "- Transformations of chunks to generate more vectors for improved retrieval\n",
    "\n",
    "The `RAGVectorStore`, in combination with other components, is designed to address this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2631007b-61df-4a1d-93d8-e1ae6d85193e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "For the sample, we are using the set of documents from Wikipedia.\n",
    "We would like to answer questions related to mathematics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66ec62-500b-44a9-b14c-bc942801260c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "> This notebook is not intended to demonstrate the relevance of each optimisation approach. The example is based on too few documents for that. It is simply intended to illustrate an implementation of an advanced RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "771c76125e1ae179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:06.975187Z",
     "start_time": "2024-02-27T15:23:55.035019Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chromadb in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.4.23)\r\n",
      "Requirement already satisfied: kaleido in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.2.1)\r\n",
      "Requirement already satisfied: python-multipart in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.0.9)\r\n",
      "Requirement already satisfied: wikipedia in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (1.4.0)\r\n",
      "Requirement already satisfied: lark in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (1.1.9)\r\n",
      "Requirement already satisfied: cohere in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (4.51)\r\n",
      "Requirement already satisfied: build>=1.0.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.0.3)\r\n",
      "Requirement already satisfied: requests>=2.28 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (2.6.2)\r\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.7.3)\r\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.110.0)\r\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.27.1)\r\n",
      "Requirement already satisfied: numpy>=1.22.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.24.4)\r\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (3.4.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (4.10.0)\r\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (3.4.0)\r\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.17.1)\r\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.23.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.23.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.44b0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.23.0)\r\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.15.2)\r\n",
      "Requirement already satisfied: pypika>=0.48.9 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.48.9)\r\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (4.66.2)\r\n",
      "Requirement already satisfied: overrides>=7.3.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (7.7.0)\r\n",
      "Requirement already satisfied: importlib-resources in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (6.1.2)\r\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (1.62.0)\r\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (4.1.2)\r\n",
      "Requirement already satisfied: typer>=0.9.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (0.9.0)\r\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (29.0.0)\r\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (8.2.3)\r\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (6.0.1)\r\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (4.1.0)\r\n",
      "Requirement already satisfied: orjson>=3.9.12 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from chromadb) (3.9.15)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from wikipedia) (4.12.3)\r\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from cohere) (3.9.3)\r\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from cohere) (2.2.1)\r\n",
      "Requirement already satisfied: fastavro<2.0,>=1.8 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from cohere) (1.9.4)\r\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from cohere) (6.11.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from cohere) (2.2.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\r\n",
      "Requirement already satisfied: packaging>=19.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (23.2)\r\n",
      "Requirement already satisfied: pyproject_hooks in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (1.0.0)\r\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\r\n",
      "Requirement already satisfied: six>=1.9.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\r\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.28.1)\r\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\r\n",
      "Requirement already satisfied: requests-oauthlib in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\r\n",
      "Requirement already satisfied: coloredlogs in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\r\n",
      "Requirement already satisfied: flatbuffers in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\r\n",
      "Requirement already satisfied: protobuf in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\r\n",
      "Requirement already satisfied: sympy in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\r\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\r\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.23.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\r\n",
      "Requirement already satisfied: opentelemetry-proto==1.23.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.23.0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.44b0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\r\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.44b0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.44b0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\r\n",
      "Requirement already satisfied: opentelemetry-util-http==0.44b0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.44b0)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.8.0)\r\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\r\n",
      "Requirement already satisfied: asgiref~=3.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\r\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.16.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.6)\r\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\r\n",
      "Requirement already satisfied: h11>=0.8 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\r\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\r\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\r\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\r\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\r\n",
      "Requirement already satisfied: websockets>=10.4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from beautifulsoup4->wikipedia) (2.5)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\r\n",
      "Requirement already satisfied: filelock in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (4.3.0)\r\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.1)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_rag in /home/pprados/workspace.bda/langchain-rag (0.0.0)\r\n",
      "Requirement already satisfied: langchain_core in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.1.27)\r\n",
      "Requirement already satisfied: langchain_community in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.0.24)\r\n",
      "Requirement already satisfied: langchain-openai in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.0.5)\r\n",
      "Requirement already satisfied: langchain_qa_with_references in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (0.0.330)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (6.0.1)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (4.3.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (1.33)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (0.1.9)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (2.6.2)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_core) (8.2.3)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_community) (2.0.27)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_community) (3.9.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_community) (0.6.4)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_community) (1.24.4)\r\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain-openai) (1.12.0)\r\n",
      "Requirement already satisfied: tiktoken<0.6.0,>=0.5.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain-openai) (0.5.2)\r\n",
      "Requirement already satisfied: langchain>=0.0.330 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langchain_qa_with_references) (0.1.9)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\r\n",
      "Requirement already satisfied: idna>=2.8 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core) (3.6)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from anyio<5,>=3->langchain_core) (1.3.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.0)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (2.4)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_core) (3.9.15)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (2.16.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_core) (2024.2.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from tiktoken<0.6.0,>=0.5.2->langchain-openai) (2023.12.25)\r\n",
      "Requirement already satisfied: httpcore==1.* in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/pprados/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install chromadb kaleido python-multipart wikipedia lark cohere\n",
    "%pip install langchain_rag langchain_core langchain_community langchain-openai langchain_qa_with_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "209401ccb84bfa17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:06.983551Z",
     "start_time": "2024-02-27T15:24:06.978963Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"What is the difference between pure and applied mathematics?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86beba-b0bd-4690-a77b-ae133d3750be",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Prepare the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a365c-24a7-4deb-8349-2effde6df90b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "To start with, we create a working directory to store all sorts of things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84786a92-1c31-4c8c-9543-22e467d9dfd4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Then we add a small function to display lists of documents, with a selection of metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "505aae5e89ee147e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:06.993226Z",
     "start_time": "2024-02-27T15:24:06.985233Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "import logging\n",
    "import pathlib\n",
    "import tempfile\n",
    "import tiktoken\n",
    "from typing import List, Union\n",
    "\n",
    "# Activate logging and prints\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "\n",
    "CALLBACKS = []\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "def pretty_print_docs(\n",
    "        docs: Union[str, List[Document]], metadatas=[], kind: str = \"Variations\"\n",
    "):\n",
    "    def print_metadata(d):\n",
    "        s = \",\\n\".join(\n",
    "            [f\"{metadata}={repr(d.metadata.get(metadata))}\" for metadata in metadatas]\n",
    "        )\n",
    "        if s:\n",
    "            return f\"\\n\\033[92m{s}\\033[0m\"\n",
    "        return \"\"\n",
    "\n",
    "    def print_doc(d, i):\n",
    "        r = f\"\\033[94m{kind} {i + 1}:\\n{d.page_content[:80]}\"\n",
    "        if len(d.page_content) > 80:\n",
    "            r += f\"...[:{max(0, len(d.page_content) - 80)}]\"\n",
    "        r+=f\" {len(encoding.encode(d.page_content))} toks\"\n",
    "        r += f\"\\033[0m{print_metadata(d)}\"\n",
    "        return r\n",
    "\n",
    "    if isinstance(docs, list):\n",
    "        print(f\"\\n{'-' * 40}\\n\".join([print_doc(d, i) for i, d in enumerate(docs)]))\n",
    "    else:\n",
    "        print(f\"\\033[92m{docs}\\033[0m\")\n",
    "\n",
    "ROOT_PATH = tempfile._gettempdir() + \"/rag\"\n",
    "pathlib.Path(ROOT_PATH).mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629c1609-51c9-4983-be9f-7e470965a2b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Select providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa8340e2-1b4a-4b93-b407-268f8a698496",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.021258Z",
     "start_time": "2024-02-27T15:24:06.996293Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"  # Set api key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd2a2d9-de21-4336-9711-413f1e9c83b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Select the embedding implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e3ce9c7-fafc-493e-b5b4-93f64f81a8ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.121301Z",
     "start_time": "2024-02-27T15:24:07.022712Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select OpenAI implementation\n",
    "from langchain_openai import *\n",
    "\n",
    "model_id=\"gpt-3.5-turbo-instruct\"\n",
    "\n",
    "openai_embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "54cc5d45-573b-4540-8738-16115818a9d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.127375Z",
     "start_time": "2024-02-27T15:24:07.122825Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a cache for embeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "CACHE_EMBEDDING_PATH = ROOT_PATH + \"/cache_embedding\"\n",
    "fs = LocalFileStore(CACHE_EMBEDDING_PATH)\n",
    "\n",
    "\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    openai_embeddings,\n",
    "    fs,\n",
    "    namespace=openai_embeddings.model if hasattr(openai_embeddings, \"model\") else \"unknown\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eae5c786-0352-48c6-8629-7b6f0eee6129",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.135537Z",
     "start_time": "2024-02-27T15:24:07.129157Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k=4 context_size=4096 prompt_tokens=409, doc_tokens=717, input_tokens=3277, output_tokens=819\n"
     ]
    }
   ],
   "source": [
    "# Calculates the parameters\n",
    "nb_documents_to_import = 3  # How many documents should be imported from Wikipedia?\n",
    "top_k = 4  # How many chunks should be injected in the prompt to answer the question?\n",
    "doc_content_chars_max=4000   # First chars for wikipedia docs\n",
    "\n",
    "embeddings_tokens_limit= openai_embeddings.embedding_ctx_length\n",
    "\n",
    "context_size = OpenAI.modelname_to_contextsize(model_id)  # The GPT3.5 limit\n",
    "\n",
    "# 10% for the prompt without context\n",
    "prompt_tokens = int(context_size * (10 / 100))  \n",
    "\n",
    "# 20% for the response\n",
    "output_tokens = int(context_size * (20 / 100))  \n",
    "\n",
    "# Minimum tokens for one document\n",
    "min_doc_tokens = 200\n",
    "\n",
    "# Maximum size for each documents to inject\n",
    "doc_tokens = (context_size - prompt_tokens - output_tokens ) // top_k\n",
    "if doc_tokens > embeddings_tokens_limit:\n",
    "    top_k = (context_size - prompt_tokens - output_tokens ) // embeddings_tokens_limit\n",
    "elif doc_tokens < min_doc_tokens:\n",
    "    top_k = (context_size - prompt_tokens - output_tokens ) // min_doc_tokens\n",
    "\n",
    "# Then, the maximum nomber of tokens for the prompt\n",
    "input_tokens = context_size - output_tokens\n",
    "\n",
    "print(f\"{top_k=} {context_size=} {prompt_tokens=}, {doc_tokens=}, {input_tokens=}, {output_tokens=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39c804-d033-4bb3-adf0-ec8f5e0d9168",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Select the LLM\n",
    "Before starting, we need to:\n",
    "- Set the environment variables\n",
    "- Choose a language model (LLM), determine the context size, and set the maximum number of tokens for generation\n",
    "- Enable all caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "53237ba8-cd7c-4cfc-bafe-d980a53ddbbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.226278Z",
     "start_time": "2024-02-27T15:24:07.136913Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    model=model_id,\n",
    "    temperature=0.2,\n",
    "    max_tokens=output_tokens,  # Maximum possible\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e12bd3f44158a74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:07.253803Z",
     "start_time": "2024-02-27T15:24:07.228070Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a cache\n",
    "from langchain_core import globals\n",
    "from langchain_community.cache import SQLiteCache\n",
    "\n",
    "LANCHAIN_CACHE_PATH = ROOT_PATH + \"/cache_llm\"\n",
    "globals.set_llm_cache(SQLiteCache(database_path=LANCHAIN_CACHE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0bea32-373d-400d-a887-9aadc2485ab6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Load the documents\n",
    "\n",
    "We want to retrieve documents about mathematics from wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af6a3c4bb3423122",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.839083Z",
     "start_time": "2024-02-27T15:24:07.257302Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mDocuments 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3920] 814 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mDocuments 2:\n",
      "Mathematical Reviews is a journal published by the American Mathematical Society...[:3920] 822 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mDocuments 3:\n",
      "The philosophy of mathematics is the branch of philosophy that studies the assum...[:3920] 762 toks\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "documents = WikipediaRetriever(\n",
    "    top_k_results=nb_documents_to_import, \n",
    "    doc_content_chars_max=doc_content_chars_max\n",
    ").get_relevant_documents(\"mathematic\")\n",
    "pretty_print_docs(documents, kind=\"Documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20ff47d-933e-47be-9849-bccc78cf9309",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Transform documents\n",
    "The idea is to transform a document into multiple versions and calculate a vector for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97b6e300-50f4-41ae-a524-05030c2c865c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.843449Z",
     "start_time": "2024-02-27T15:24:10.840192Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import *\n",
    "from langchain_rag.document_transformers import *\n",
    "from langchain_rag.document_transformers import DocumentTransformerPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e513cf-6ac8-4121-81b9-b961afd52d6f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The first step is to split the document to ensure compatibility with the `max_input_tokens`. This could be a transformation pipeline, for an initial wiki split, followed by a size split for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ff426ce-ffe1-4f90-927f-af83ce37cef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.850969Z",
     "start_time": "2024-02-27T15:24:10.845155Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "wiki_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"={1,6} .* ={1,6}\",  # See https://en.wikipedia.org/wiki/Help:Wikitext\n",
    "        \"\\n----+\\n\",            \n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "    ],\n",
    "    chunk_size=doc_content_chars_max,\n",
    "    chunk_overlap=0,\n",
    "    is_separator_regex=True)\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=doc_tokens, chunk_overlap=0)\n",
    "parent_transformer = DocumentTransformerPipeline(transformers=[wiki_splitter,token_splitter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a640d55a-a466-4de1-abfe-4d5c1d2d76a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's test the transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbb10dc0-6cf2-4e14-b55c-bb846ba97515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.863451Z",
     "start_time": "2024-02-27T15:24:10.852379Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'before:3 documents, after:6 chunks'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_documents = parent_transformer.transform_documents(documents)\n",
    "f\"before:{len(documents)} documents, after:{len(chunk_documents)} chunks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b9ef168-4892-400f-be6a-fc714f95c325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.871918Z",
     "start_time": "2024-02-27T15:24:10.865245Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mChunk 1:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3338] 688 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 2:\n",
      " Latin, and in English until around 1700, the term mathematics more commonly mea...[:502] 126 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 3:\n",
      "Mathematical Reviews is a journal published by the American Mathematical Society...[:3352] 699 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 4:\n",
      " or lower MCQ than average. The 2018 All Journal MCQ is 0.41.\n",
      "\n",
      "\n",
      "== Current Mathe...[:488] 123 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 5:\n",
      "The philosophy of mathematics is the branch of philosophy that studies the assum...[:3639] 714 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mChunk 6:\n",
      "\" remains elusive. Investigations into this issue are known as the foundations o...[:201] 48 toks\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(chunk_documents, kind=\"Chunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79651e78d2831fcc",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We need multiple variations for each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09aa4959-1325-43cd-a22e-0f7c983c8be5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:10.877218Z",
     "start_time": "2024-02-27T15:24:10.873209Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_transformer = DocumentTransformers(\n",
    "    transformers=[\n",
    "        GenerateQuestionsTransformer.from_llm(llm),\n",
    "        SummarizeTransformer.from_llm(llm),\n",
    "        CopyDocumentTransformer(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74358ce-b013-4729-a71b-ee4c82f0d51f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "> **Note:** that we require all transformations for each chunk, including the original chunk. This is why we include the `CopyDocumentTransformer()`.\n",
    "\n",
    "Now, let's test the transformation for the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63cf0377ba48d2ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:13.130267Z",
     "start_time": "2024-02-27T15:24:10.879042Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mVariations 1:\n",
      "What are the major subdisciplines of modern mathematics? 12 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 2:\n",
      "How are abstract objects used in mathematical proofs? 9 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 3:\n",
      "What was the original meaning of the word \"mathematics\" in Ancient Greek? 16 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 4:\n",
      "SUMMARY:\n",
      "Mathematics is a field of study that deals with numbers, formulas, shap...[:445] 115 toks\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[94mVariations 5:\n",
      "Mathematics is an area of knowledge that includes the topics of numbers, formula...[:3338] 688 toks\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "variations_of_chunks = chunk_transformer.transform_documents(chunk_documents[:1])\n",
    "# Select the variations for the first chunk\n",
    "pretty_print_docs(variations_of_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be062dd-cf9c-423b-be8b-67a8566b354e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We see 3 questions, a summary of the chunk and the original chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c2f4a8b3c8248",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "![Tree of variations](plantuml/variations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a594c2a-1ddc-4eb7-a7ba-922923fe5dae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Saving all Variations in a Vector Store\n",
    "Now, our goal is to store the chunks and their respective variations in a vector store. During retrieval, the process begins by fetching the smaller chunks but then involves looking up the parent IDs for those chunks and returning the original chunk.\n",
    "\n",
    "A specialized vector store is designed for this purpose: the `RAGVectorStore`.\n",
    "It's not a standalone vector store but rather a wrapper for another vector store. When you add a document, the document undergoes transformation with the `parent_transformer`, and each chunk is enriched with various versions through the `chunk_transformer`. Each parameter is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d873d0e0c5f64d9",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Build step by step\n",
    "First, we need to create some persistent components:\n",
    "- A standard vector store\n",
    "- A `Docstore` to store each original chunk returned by the *retriever* and the relationship between the document and chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc155113-dd16-4c73-a13c-80d428bd7923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:13.154392Z",
     "start_time": "2024-02-27T15:24:13.131897Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "import chromadb.segment.impl.metadata.sqlite\n",
    "import chromadb.segment.impl.vector.local_persistent_hnsw\n",
    "chromadb.segment.impl.metadata.sqlite.logger.setLevel(logging.ERROR)\n",
    "chromadb.segment.impl.vector.local_persistent_hnsw.logger.setLevel(logging.ERROR)\n",
    "\n",
    "VS_PATH = ROOT_PATH + \"/vs\"\n",
    "chroma_vectorstore = Chroma(\n",
    "    collection_name=\"all_variations_of_chunks\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=VS_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d189e7e-3e59-43f0-9a8c-92fd7844c393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:13.162382Z",
     "start_time": "2024-02-27T15:24:13.156284Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DOCSTORE_PATH = ROOT_PATH + \"/chunks\"\n",
    "from langchain.storage import EncoderBackedStore,LocalFileStore\n",
    "import pickle\n",
    "\n",
    "docstore = EncoderBackedStore[str, Document](\n",
    "    store=LocalFileStore(root_path=DOCSTORE_PATH),\n",
    "    key_encoder=lambda x: x,\n",
    "    value_serializer=pickle.dumps,\n",
    "    value_deserializer=pickle.loads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266663f2-bb6a-46dd-84cc-0ec67a5bf24e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "All documents must have a unique ID in their metadata. \n",
    "Then, it's possible to use the advanced `RAGVectorStore`. \n",
    "It's a wrapper around a standard vector store, specialized for managing different transformations and the lifecycle of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4fafbad-c577-40ae-8543-a145d9ca7f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:13.169796Z",
     "start_time": "2024-02-27T15:24:13.164445Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_rag.vectorstores import RAGVectorStore\n",
    "\n",
    "variation_k = 10\n",
    "rag_vectorstore = RAGVectorStore(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    docstore=docstore,\n",
    "    source_id_key=\"source\",  # Uniq id of documents\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    #search_kwargs={\"k\": variation_k},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039782f-9f63-4885-be09-ba9f7555b2cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now, it's time to add documents to this *special* vector store.\n",
    "- If the `parent_transformer` is set, the document is transformed into a new list of chunk documents (generally, this is a split phase).\n",
    "- Then, if the `chunk_transformer` is set, each chunk document is transformed to generate some variations.\n",
    "- Each transformation of all chunks is added to the destination vector store (in this case, it's referred to as \"chroma\").\n",
    "- All chunks are saved in the `Docstore` with the list of all associated variations.\n",
    "- All IDs of chunks generated for each document are saved in the `Docstore`. This makes it possible to remove the document and all associated chunks when needed.\n",
    "- `variation_k` variations is returned in the delegate vectorstore\n",
    "\n",
    "> This takes time, because the transformations are carried out when the documents are added. Among other things, an LLM must be invoked to produce a summary of each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ecd8eba9-36aa-4ed6-b32d-a7eef48289a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:14.000395Z",
     "start_time": "2024-02-27T15:24:13.171703Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[43mrag_vectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m chroma_vectorstore\u001b[38;5;241m.\u001b[39mpersist()\n\u001b[1;32m      3\u001b[0m ids\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/langchain_rag/vectorstores/rag_vectorstore.py:303\u001b[0m, in \u001b[0;36mRAGVectorStore.add_documents\u001b[0;34m(self, documents, ids, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     transformed_chunk\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_id_key] \u001b[38;5;241m=\u001b[39m chunk_id\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Save the transformed versions\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m transformed_persistance_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_transformed_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Inject id of transformed ids in the chuck document\u001b[39;00m\n\u001b[1;32m    307\u001b[0m chunk_doc\u001b[38;5;241m.\u001b[39mmetadata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchild_ids_key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    308\u001b[0m     transformed_persistance_ids\n\u001b[1;32m    309\u001b[0m )\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/langchain_core/vectorstores.py:139\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    138\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/langchain_community/vectorstores/chroma.py:297\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/chromadb/api/models/Collection.py:487\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/chromadb/api/segment.py:467\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record(coll, r)\n\u001b[1;32m    466\u001b[0m     records_to_submit\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_producer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_to_submit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/workspace.bda/langchain-rag/.venv/lib/python3.11/site-packages/chromadb/db/mixins/embeddings_queue.py:172\u001b[0m, in \u001b[0;36mSqlEmbeddingsQueue.submit_embeddings\u001b[0;34m(self, topic_name, embeddings)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001b[39;00m\n\u001b[1;32m    171\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RETURNING seq_id, id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pypika doesn't support RETURNING\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m results \u001b[38;5;241m=\u001b[39m cur\u001b[38;5;241m.\u001b[39mexecute(sql, params)\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Reorder the results\u001b[39;00m\n\u001b[1;32m    174\u001b[0m seq_ids \u001b[38;5;241m=\u001b[39m [cast(SeqId, \u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    175\u001b[0m     results\n\u001b[1;32m    176\u001b[0m )  \u001b[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "ids = rag_vectorstore.add_documents(documents)\n",
    "chroma_vectorstore.persist()\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a0119fbd62cda",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "While conducting the search, an embedding is computed for the query and subsequently compared to the embeddings of all the transformed chunks. The metadata for each transformed chunk contains a reference to the ID of the original chunk, allowing for the retrieval of the respective chunk."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5c65eac9a6017",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The IDs returned by `add_documents()` consist of a list of `document IDs`. You can utilize these IDs to remove all documents, related chunks and variations.\n",
    "\n",
    "When you examine the langchain API, you may wonder where to store the document IDs from the vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b4c8ac0660246",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-27T15:24:14.003458Z",
     "start_time": "2024-02-27T15:24:14.003318Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretty_print_docs(\n",
    "    rag_vectorstore.search(query=query, search_type=\"similarity\"),\n",
    "    [\"source\", \"_chunk_id\"],\n",
    "    kind=\"Chunk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ad52eae299824",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete documents, chunks and variations\n",
    "rag_vectorstore.delete(ids=ids)\n",
    "chroma_vectorstore.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba9eb40d3768f7",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Index Vector Store\n",
    "To manage the lifecycle of the documents in the vector store, you can utilize an `index()`.\n",
    "A `RecordManager` can keep track of the evolution of each document. Use langchain `index()` to import the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ea4486d47ea54",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.indexes import index, SQLRecordManager\n",
    "\n",
    "record_manager = SQLRecordManager(\n",
    "    namespace=\"record_manager_cache\", db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\"\n",
    ")\n",
    "record_manager.create_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29511638aa0cf089",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Save all the information in:\n",
    "# - record manager\n",
    "# - docstore\n",
    "# - vectorstore\n",
    "index_kwargs = {\n",
    "    \"record_manager\": record_manager,\n",
    "    \"vector_store\": rag_vectorstore,\n",
    "    \"source_id_key\": \"source\",\n",
    "}\n",
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be721fb41e1d9103",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Alternative factory\n",
    "To simplify the creation of the persistance ecosystem, you can use the `from_vs_in_memory` method for in-memory usage only, and `from_vs_in_sql` for usage with SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98aaaa84ea1149c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "```python\n",
    "rag_vectorstore, index_kwargs = RAGVectorStore.from_vs_in_memory(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    source_id_key=\"source\",\n",
    ")\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    cleanup=\"incremental\",\n",
    "    **index_kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84d627e4f9eb33",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "```python\n",
    "rag_vectorstore, index_kwargs = RAGVectorStore.from_vs_in_sql(\n",
    "    vectorstore=chroma_vectorstore,\n",
    "    parent_transformer=parent_transformer,\n",
    "    chunk_transformer=chunk_transformer,\n",
    "    source_id_key=\"source\",\n",
    "    db_url=f\"sqlite:///{ROOT_PATH}/record_manager.db\",\n",
    ")\n",
    "index(\n",
    "    docs_source=documents,\n",
    "    cleanup=\"incremental\",\n",
    "    **index_kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95ff9c58b897997",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "If you import the same documents, you will notice that all documents are skipped. \n",
    "> Without using `index()`, in a classical vector store, the same document will be present twice. This has the same effect as dividing the `top_k` by two during the search! Because 2 different documents with the same content are returned by the vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c3fdc0ec4c5fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4926718dd8c6b87",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "If your document is changed, the previous version is deleted.\n",
    "> **Note:** Only the updated document is transformed ! So you save on treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dd66e8de8dc70",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "documents[0].page_content += \" Is changed.\"\n",
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348aa8c04f101a3b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "To delete the old records, use the `full` strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c68d044cfeef5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "del documents[-1]\n",
    "result = index(docs_source=documents, cleanup=\"full\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d1a1a-6ca2-490d-9086-5ecf221981a4",
   "metadata": {},
   "source": [
    "To delete the all records, use the full strategy and an empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbd925-fb40-4a1f-887d-b3cdfce8019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = index(docs_source=[], cleanup=\"full\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d91de-2c2d-4171-9fc0-99a0ed631e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-import all documents\n",
    "result = index(docs_source=documents, cleanup=\"incremental\", **index_kwargs)\n",
    "chroma_vectorstore.persist()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec51edafcdd6d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "It's important to note that there are three ways to save parts of the data:\n",
    "\n",
    "- In the *vector store*: this includes the bucket, metadata, and the associated embedding vectors.\n",
    "- In the *doc store*: this covers the original bucket and the relationship between parent and chunks before the *chunk transformations*.\n",
    "- In the *SQLRecordManager*: this involves the references of the parent document or chunks.\n",
    "\n",
    "> **Note:** Each source does not manage transactions. If a problem occurs while adding a document, it is highly likely that the sources will be inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2981b01e756e9096",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Use advanced retrievers\n",
    "Just like with the standard vector store, you can convert the `RAGVectorStore` into a `Retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec70b4b3dcc80eb8",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_retriever = rag_vectorstore.as_retriever()\n",
    "selected_chunks = rag_retriever.get_relevant_documents(query)\n",
    "pretty_print_docs(selected_chunks, [\"source\", \"_chunk_id\"], \"Chunk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d79dba17a046faa",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Specialized Retrievers\n",
    "It's possible to combine multiple retrievers or use specialized retrievers for advanced applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f219067ca4a98",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## SelfQueryRetriever\n",
    "The `SelfQueryRetriever` can generate a metadata filter. We use it to provide the option to filter the chunks by the title of the original document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8ab4707aef773",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the document.\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "]\n",
    "document_content_description = \"Documents on mathematics\"\n",
    "self_retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    rag_vectorstore,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    use_original_query=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "pretty_print_docs(\n",
    "    self_retriever.get_relevant_documents(\n",
    "        \"In the document 'History of mathematics', \" + query\n",
    "    ),\n",
    "    [\"title\"],\n",
    "    kind=\"Chunk\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f98bdc3a46341",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "> **Note:** We set `use_original_query` because, otherwise, the question can be modified if there is no filter on the metadata to be applied. Which is irrelevant (see [ticket](https://github.com/langchain-ai/langchain/pull/9309) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e243eadf938e2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## MergerRetriever\n",
    "With filter, we can obtain a retriever specialized in summaries. But then you have to use chroma directly, in order to query the variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aca35b60b7c847",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary_retriever = chroma_vectorstore.as_retriever(\n",
    "    search_kwargs={\"filter\": {\"transformer\": {\"$eq\": 'SummarizeTransformer'}}}\n",
    ")\n",
    "pretty_print_docs(summary_retriever.get_relevant_documents(query), [\"transformer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c261a17c2a969d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Just for the demo, we will combine it with the chunk retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf6111bcbfc6c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.merger_retriever import MergerRetriever\n",
    "\n",
    "merge_retriever = MergerRetriever(retrievers=[self_retriever, summary_retriever])\n",
    "pretty_print_docs(\n",
    "    merge_retriever.get_relevant_documents(query), [\"transformer\"], kind=\"Chunk\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577ae97cec80e50",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## MultiQueryRetriever\n",
    "Retrieval results may vary with minor changes in query phrasing or if the embeddings do not accurately capture the data's semantics. The `MultiQueryRetriever` streamlines the prompt-tuning process by employing an LLM to generate multiple queries from diverse perspectives based on a user input query. For each query, it retrieves a collection of pertinent documents and combines the unique results from all queries to obtain a larger set of potentially relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be992243890cc9",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever,logger\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "query = \"What is the difference between pure and applied mathematics?\"\n",
    "\n",
    "# Generate 3 questions from the user questions, and these version to find a better candidats in vectorstore\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=merge_retriever,\n",
    ")\n",
    "\n",
    "pretty_print_docs(multi_query_retriever.get_relevant_documents(query), [\"transformer\"],kind=\"Chunk\")\n",
    "final_retriever = multi_query_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7c70d5449684d8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Others...\n",
    "Other strategies can be added. This depends on the project, and above all on their relevance to the quality of the documents handled.\n",
    "\n",
    "- The `EnsembleRetriever` takes a list of retrievers as input and ensemble the results of their `get_relevant_documents()` methods and rerank the results based on the [Reciprocal Rank Fusion algorithm](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf).\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369a18f602a1b83",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "At this stage, when we employ the retriever:\n",
    "\n",
    "- Multiple queries are generated to locate the relevant documents (via `multi_query_retriever`).\n",
    "- For each query:\n",
    "    - Variations are used for better selection of chunks (via `RagVectorstore`)\n",
    "    - Both the original chunk and the chunk summary are retrieved (via `MergeRetriever`).\n",
    "    - If feasible, a metadata filter is applied (via `SelfQueryRetriever`)\n",
    "- Only this selected candidate can be used to answer a question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231bfd97367dc51",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Use a compressor\n",
    "It's possible to use a *compressor*, to filter the selection, and reduce the volume of each chunks.\n",
    "\n",
    "You can combine some filters in a pipeline.\n",
    "- The [EmbeddingsFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#embeddingsfilter) can add a similarity threshold between the query and documents\n",
    "- The [CohereRerank](https://python.langchain.com/docs/integrations/retrievers/cohere-reranker) can re-rank the chunks (Need API key).\n",
    "- The [LLMChainFilter](https://python.langchain.com/docs/modules/data_connection/retrievers/contextual_compression#llmchainfilter) decide which of the initially retrieved documents to filter out and which ones to return, without manipulating the document contents.\n",
    "- THe [LongContextReorder](https://python.langchain.com/docs/integrations/retrievers/merger_retriever#re-order-results-to-avoid-performance-degradation) to reorder the selected documents\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbede89e25ee4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import EmbeddingsFilter\n",
    "\n",
    "embeddings_filter = EmbeddingsFilter(\n",
    "    embeddings=embeddings,\n",
    "    similarity_threshold=0.7,  # Threshold for determining when two documents are redundant.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd165fb056847283",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "long_context_reorder = LongContextReorder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1371cafbc000ab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine compressors\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "\n",
    "compressor = DocumentCompressorPipeline(\n",
    "    transformers=[\n",
    "        # embeddings_filter, # Deactivated, so as not to conflict with RAGVectorstore\n",
    "        long_context_reorder,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784853ec5a5e5b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "> **Note:** We do not use `embeddings_filter`, because a fragment can have a proximity < 0.7, but one of its variations a higher proximity. We want to keep the fragment in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10c8c0a080849fd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now, we can add a filter with our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537aa32a60d7b71d",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "\n",
    "query = \"What is the difference between pure and applied mathematics?\"\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=multi_query_retriever\n",
    ")\n",
    "\n",
    "pretty_print_docs(compression_retriever.get_relevant_documents(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613c2674527f644",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "final_retriever = compression_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c4be830f438ca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The final map is:\n",
    "\n",
    "![Chain of retrievers](plantuml/all_retrievers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e195db90457352",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Asking a Question\n",
    "\n",
    "Now, it's possible to utilize this architecture to pose a question. We hope that all these optimisations will lead to a better selection of chunks, based on the user's question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e146b3fb5aa1a8c4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "A problem can arise if the number of documents to be analysed is too large for the size of the prompt.\n",
    "Several strategies are available to manage this, identified by the \n",
    "[`chain_type`](https://python.langchain.com/docs/use_cases/question_answering/vector_db_qa#chain-type) parameter.\n",
    "\n",
    "> **Note 1**: The version `load_qa_chain()` and `RetrievalQAWithSourcesChain` are subject to hallucinations. They can respond without using the documents provided. This is not the case for `RetrievalQAWithReferencesChain` and `RetrievalQAWithReferencesAndVerbatimsChain`.\n",
    "\n",
    "> **Note 2**: The `map_reduce` chain type, use an approach similar to *compressor*, but working recursively to keep the number of tokens below a threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d6cea511e95c6",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "query = \"What is the difference between pure and applied mathematics?\"\n",
    "\n",
    "chain = load_qa_chain(\n",
    "    llm,\n",
    "    \n",
    "    chain_type=\"map_reduce\",  # \"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"\n",
    ")\n",
    "result = chain.invoke(\n",
    "    {\n",
    "        \"input_documents\": final_retriever.get_relevant_documents(query),\n",
    "        \"question\": query,\n",
    "    },\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "print(result[\"output_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5178548aed66397",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "If the documents have `sources` and the URLs are not too large, you can use `RetrievalQAWithSourcesChain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d24ebb6d278bac",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"map_reduce\",  # \"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"\n",
    "    retriever=final_retriever,\n",
    "    callbacks=CALLBACKS,\n",
    ")\n",
    "result = chain.invoke(query)\n",
    "print(result[\"answer\"])\n",
    "pretty_print_docs(result[\"sources\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49beb23b22096ce2",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean up\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree(ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62089560-bf04-4426-a5f3-acfa656edbd5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-07T07:41:47.451317026Z"
    },
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "- [Why Your RAG Is Not Reliable in a Production Environment](https://towardsdatascience.com/why-your-rag-is-not-reliable-in-a-production-environment-9e6a73b3eddb)\n",
    "- [Forget RAG, the Future is RAG-Fusion](https://towardsdatascience.com/forget-rag-the-future-is-rag-fusion-1147298d8ad1)\n",
    "- [A first intro to Complex RAG](https://medium.com/enterprise-rag/a-first-intro-to-complex-rag-retrieval-augmented-generation-a8624d70090f)\n",
    "- [Advanced RAG Techniques: an Illustrated Overview](https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6)\n",
    "- [weblangchain](https://blog.langchain.dev/weblangchain/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "langchain-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
